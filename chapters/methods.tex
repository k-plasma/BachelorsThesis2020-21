\section{Data Science}

\todo{It's critical that this section JUSTIFIES THE TOOLS I'm using. Think of a plumber.}

\todo{I'll have to JUSTIFY my approach}

\todo{I'll have to justify why I am selecting certain tools to answer my Research questions. That is the questions in the Diagram in Related Works}

\todo{In addition, extract questions that go into a table. Justify why you have selected the sections and reference the Literature review. Maybe not relevant to my work.}
Data Science is a subset of Computer Science and Mathematics. This subset introduces a new paradigm which creates algorithms for computers and robots. It combines statistics with Computer Science. Data Science also involves the use of machine learning algorithms for prediction.

Machine Learning is a novel part of Data Science and it encompasses the ability of machines to learn from examples. These models are categorized as either \textbf{\textit{Supervised}} or \textbf{\textit{Unsupervised}} Machine Learning models. 

In the field of Data Science, mathematics is very important. This is because principles within mathematics help in the detection of patterns and algorithm construction. In the application of such algorithms in data science, the comprehension of different conceptions of statistics and probability theory is crucial. Notions include Regression, Maximum Likelihood Estimation, distribution's comprehension (Binomial, Bernoulli, Gaussian (Normal)), and Bayes's Theorem.

\subsection{Supervised Learning} %Dev Later
Supervised learning is further categorized as  either \textbf{\textit{Regression}} or \textbf{\textit{Classification.}} The main difference between Regression and Classification is that the output variable in Regression is numerical while that for Classification is categorical. In other words, Regression predicts a quantity while  Classification predicts a label.


\subsubsection{Machine Learning model - Regression}
In this 1998 article, \cite{zeger1988regression} Scot Zeger posits the analysis of a regression model with a time series. Linear Regression is a basic offshoot of Regression. The predicted output of a Linear Regression model is continuous with a constant slope. The 2 main types of Linear Regression are simple and multivariate regression. 

Simple linear regression can be explained with the slope-intercept form, where \textit{m} and \textit{b} are the variables the algorithm learns to produce the most accurate predictions. \textit{x} in this case represents the input data while \textit{y} the prediction.

\begin{equation}
	y = m x + b
\end{equation}

Multivariate regression is a method with more than one output variable that calculates a single regression model. If a multivariate regression model has more than one predictor variable, the system is a multivariate multiple regression.


\subsubsection{Machine Learning model - Classification}

In this 2006 paper by Kevin P. Murphy \cite{murphy2006naive} he defines a \textbf{classifier} as a function \textit{f} that maps input feature vectors to output classes. This classifier is derived from the \textbf{Bayes' Theorem}

A classification is a tool used to assign groups to a data set in order to assist in detailed forecasts and analysis. You are introduced to an existing data-set with classification algorithms and are aware of the groups of individual instances; with this information, a predictive model can then be created to solve the following problem: For any future instance in the data-set to which a particular instance belongs. Max Entropy, K-Nearest Neighbor, and Naive Bayes are among the types of classification algorithms.



\begin{equation}
	\label{eq:bayes}
	P(\theta | \textbf{D}) = P(\theta ) \frac{P(\textbf{D} |\theta)}{P(\textbf{D})},
\end{equation}



\subsection{Unsupervised Learning}
%leave AS-_is



\section{Machine Learning Workflow}
One of the fundamental goals of Data Engineering is to develop data pipelines. A Data pipeline means taking data from point A (in an operational system) and then moving it to point B (into something that can be analyzed by data scientists).
The data set used for this thesis paper was gotten from the Food and Agriculture Organization of the United Nations. This organization is tasked with creating a zero-hunger World. Starting from 1945, this organization has amassed a wealth of data-set archives from its member countries all over the world. My focus is on Hungary thus, making my contribution to creating a zero-hunger Hungary.

According to the official website,\cite{division_2000}
\begin{displayquote}
	"FAOSTAT provides free access to food and agriculture data for over 245 countries and territories and covers all FAO regional groupings from 1961 to the most recent year available."
\end{displayquote} 

To achieve my goals I focused on the \textbf{Value Of Agricultural Production} and in particular the \textbf{Gross Production Value.} This value was gotten by multiplying agricultural gross production by the output prices. In the data-sets used in this thesis paper, the gross production value is expressed in US dollars. 



Different data sets are available separately. For the purpose of this thesis, I narrowed down on wheat. I adopted a consistent time-frame. 1965 to 2002. The approach to this was: Given a set of features that are consistent with a particular agricultural product, the aim is to predict the Gross Production Value.

\section{Neural Networks}
A neural network is a collection of algorithms that, through a mechanism that mimics the way the human brain works, aim to identify fundamental connections in a data set \cite{jain1999recurrent}.  Neural networks, in this context, apply to neuron frameworks, either biological or artificial in nature. Neural networks may respond to evolving inputs, so the network delivers the best possible outcome without the performance parameters having to be revamped. In the development of trading systems, the notion of neural networks, which has its origins in artificial intelligence, is rapidly gaining prominence.\citealp*{krose1993introduction}.


The biological neuron relations are modeled as weights. An excitation relation is reflected by a positive weight, whereas negative values mean inhibitory connections. Each input is updated and summarized by a weight. A linear combination is related to this practice. Finally, the amplitude of the output is regulated by an activation function. A reasonable performance range, for example, is usually between 0 and 1, or it may be âˆ’1 and 1.

\section{Recurring Neural Network}

A recurrent Neural Network(RNN) is a type of Neural Network in which the previous phase output is fed to the current stage as an input. Both the inputs and outputs are independent of each other in conventional neural networks, but in situations such as where it is important to predict the next word of a sentence, the prior words are needed and so the past words need to be recalled. RNN thus came into being, which, with the aid of a Hidden Layer, fixed this problem. Hidden State, which recalls any details about a sequence, is the key and most significant aspect of RNN.\cite{jain1999recurrent}

By giving all layers the same weights and preferences, RNN transforms the independent activation into dependent activation, thereby reducing the difficulty of increasing parameters and memorizing each previous output by giving each output to the next hidden layer as an input.
Therefore, all three layers should be merged into a single recurring layer such that the weights and biases of all the hidden layers are the same.

The formula for calculating the current state:

\[Ht = f(ht-1, Xt)\]

\textit{where} \textbf{H} is the current state, \textbf{ht-1} is the previous state and \textbf{Xt} is the inpunt state.

\subsection{GRU}  % DOn't Touch
\subsection{LSTM}
What is LSTM: It's the \textbf{Long short Term Memory} This networks rely on a gated cell to track information throughout many time-steps. How do LSTM work?

\begin{itemize}
	\item Forget: The lSTM forget their irrelevant history.
	
	
	\item Store: They perform computation to store relevant parts of new information.
	
	
	\item Update: They use the above items 1 and 2 to update their internal state.
	
	
	\item Output: Finally, they generate an output.
\end{itemize}

In summary, LSTMs help with uninterrupted gradient flow.

Testing my commit

\section{Deep Learning}
\subsection{Machine Learning vs Deep Learning}
